version: '3.8'

services:
  ai-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: findback-ai-service
    
    # Port mapping (using team-assigned port range 3300-3399)
    ports:
      - "3300:3300"
    
    # Environment variables from .env file
    env_file:
      - .env
    
    # Environment variables (can override .env)
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    
    # Volume mounts for persistent data
    volumes:
      # Persist FAISS indexes and metadata between container restarts
      - ./data:/app/data
    
    # Resource limits (appropriate for CPU-only inference)
    # Adjust based on server RAM limit (~12GB shared)
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    
    # Restart policy
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:3300/healthcheck')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# Network configuration (optional, useful if integrating with backend)
networks:
  default:
    name: findback-network
    driver: bridge

